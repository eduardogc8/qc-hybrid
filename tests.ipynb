{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "pt_w2v_patch = 'data/word_embedding/cbow_s300.txt'\n",
    "pt_w2v = KeyedVectors.load_word2vec_format(pt_w2v_patch, unicode_errors=\"ignore\")\n",
    "pt_model_w2v = {w: vec for w, vec in zip(pt_w2v.index2word, pt_w2v.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets_manager as DM\n",
    "\n",
    "chave = DM.chave_questions()\n",
    "\n",
    "ret = []\n",
    "for question in chave:\n",
    "    if question['question'] is None or question['question'].strip() == '':\n",
    "        continue\n",
    "    ret.append(question)\n",
    "chave = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = DM.separete_questions(chave)\n",
    "X = DM.words2indexes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_testv = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "aux = tokenizer.sequences_to_matrix(x_train)\n",
    "s = 8\n",
    "print(sum(aux[s]))\n",
    "print(len(x_train[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "cv = CountVectorizer(analyzer='word', strip_accents=None)\n",
    "\n",
    "cv = cv.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.inverse_transform([cv.build_tokenizer()(x_train[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.build_tokenizer()(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_layer(w2v_vocabulary, w2v_dimensions, w2v_weights):\n",
    "    w2v_input = Input(shape=(None,), dtype='int32', name='w2v_input')\n",
    "    words = Embedding(input_dim=w2v_vocabulary, output_dim=w2v_dimensions,  weights=[w2v_weights], trainable=False)(w2v_input)\n",
    "\n",
    "def bow_layer():\n",
    "    pass\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "sequence_length = x.shape[1] # 56\n",
    "vocabulary_size = len(vocabulary_inv) # 18765\n",
    "embedding_dim = 256\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 30\n",
    "\n",
    "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
    "embedding = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n",
    "reshape = Reshape((sequence_length, embedding_dim, 1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=2, activation='softmax')(dropout)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"Traning Model...\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(X_test, y_test))  # starts training\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
